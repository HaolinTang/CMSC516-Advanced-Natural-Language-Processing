{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fj4HpBBpujbC"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Sentiment Analysis_Logistics Regression \n",
        "# Adapted from Kaggle (https://www.kaggle.com/code/lakshmi25npathi/sentiment-analysis-of-imdb-movie-reviews).\n",
        "# Implemented  by Lavanya Thollamadugu\n",
        "\"\"\"\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import f1_score, accuracy_score, confusion_matrix\n",
        "from bs4 import BeautifulSoup\n",
        "import nltk\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils import shuffle\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Collect tweets for a specific movie** "
      ],
      "metadata": {
        "id": "Vt2ajnbbJQvZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tweepy\n",
        "from tweepy import *\n",
        "import pandas as pd\n",
        "import csv\n",
        "import string\n",
        " \n",
        "consumer_key = \"pDI4tjiuK0cxDZzUbiYul0bp1\"\n",
        "consumer_secret = \"W6gbnpZdClvVK2yO2Yvys3BxCPgTVog5xqfHSQ1oIOE6eR4vNw\"\n",
        "access_key= \"1567948456341426178-VJ3JXCzWoxqaKDZGinWnVoPYtvBsOa\"\n",
        "access_secret = \"qNu4ARlIHMQo67dqwAaHuJzwQdXwuG0MCvp4vq05LGpKH\"\n",
        "\n",
        "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
        "auth.set_access_token(access_key, access_secret)\n",
        " \n",
        "api = tweepy.API(auth,wait_on_rate_limit=True)\n",
        " \n",
        "csvFile = open('/content/AVATAR.csv', 'w')\n",
        "csvWriter = csv.writer(csvFile)\n",
        "search_words = \"#AVATAR\"      # enter your words\n",
        "new_search = search_words + \" -filter:retweets\"\n",
        " \n",
        "for tweet in tweepy.Cursor(api.search,q=new_search,count=10000,\n",
        "                           lang=\"en\",\n",
        "                           since_id=0).items(10000):\n",
        "    csvWriter.writerow([tweet.text.encode('utf-8')])"
      ],
      "metadata": {
        "id": "yEtA2PKk4MoL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_tweets = pd.read_csv('/content/AVATAR.csv',skiprows=1,names=['review'])"
      ],
      "metadata": {
        "id": "8E5zLijE4UlC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_tweets.size"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yKBDlGbu7m1l",
        "outputId": "478a4365-f1a6-43dc-c3cb-5103b1e13618"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4227"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_tweets.drop(df_tweets.tail(27).index,\n",
        "        inplace = True)"
      ],
      "metadata": {
        "id": "NtGrps5pAcyY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_tweets.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "blnD_6QNAsnF",
        "outputId": "aad3d40b-08ee-46e5-ab99-abd076b09501"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4170, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Data Preprocessing** "
      ],
      "metadata": {
        "id": "sxdtY4OYJciz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def process(review):\n",
        "    # remove  HTML tags\n",
        "    review = BeautifulSoup(review).get_text()\n",
        "    # remove punctuation and numbers\n",
        "    review = re.sub(\"[^a-zA-Z]\",' ',review)\n",
        "    # converting into lowercase and splitting to eliminate stopwords\n",
        "    review = review.lower()\n",
        "    review = review.split()\n",
        "    # remove stopwords\n",
        "    swords = set(stopwords.words(\"english\"))  \n",
        "    review = [w for w in review if w not in swords]      \n",
        "    return(\" \".join(review))\n",
        "\n",
        " #download the stop words\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "id": "hWfOEUqNFzmz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dac76649-ffcf-48bd-d72f-dc84d95843ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#clean the twitter data\n",
        "twitter_data = []\n",
        "for i in range(len(df_tweets[\"review\"])):        \n",
        "    twitter_data.append(process(df_tweets[\"review\"][i]))\n",
        "\n",
        "len(twitter_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NAGYWxe2FvOy",
        "outputId": "618ebe0a-31fe-49fd-b648-9f88881cb963"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4170"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#stemming function\n",
        "ps = PorterStemmer()\n",
        "\n",
        "def perform_stemming(text):\n",
        "    new_text = [ps.stem(word) for word in text.split()]\n",
        "    return ' '.join(new_text)"
      ],
      "metadata": {
        "id": "3DCZtqQbMFaV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(twitter_data[i])):\n",
        "     twitter_data[i] = perform_stemming(twitter_data[i])"
      ],
      "metadata": {
        "id": "gQ1P8iOGGXeh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# we convert twitter  data to feature vector matrix\n",
        "cv=CountVectorizer(max_features=1000)\n",
        "cv_twitter_data=cv.fit_transform(twitter_data)\n",
        "cv_twitter_data.shape"
      ],
      "metadata": {
        "id": "e7cuSaXH6rnC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#import the IMDB movire reviews data\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "df_data= pd.read_csv('/content/drive/My Drive/IMDB Dataset.csv')\n",
        "#df_data= pd.read_csv('/content/IMDB Dataset.csv')\n",
        "df_data.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z20Ub1R6vJrU",
        "outputId": "aaa0e36e-8fbb-4861-bfcf-6b07cec1a9de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50000, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_data['sentiment'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5k_K_BkfZdH4",
        "outputId": "5e663f07-fcfb-4119-8f40-0d0d8adf62db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "positive    25000\n",
              "negative    25000\n",
              "Name: sentiment, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#clean the IMDB data\n",
        "train_data = []\n",
        "for i in range(len(df_data[\"review\"])):        \n",
        "    train_data.append(process(df_data[\"review\"][i]))"
      ],
      "metadata": {
        "id": "DQM-y-ljCdCy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(train_data[i])):\n",
        "     train_data[i] = perform_stemming(train_data[i])"
      ],
      "metadata": {
        "id": "FxzfDmet2oep"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Splitting to train and test data** "
      ],
      "metadata": {
        "id": "46NnghZxJ0Ic"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "label = np.array(df_data[\"sentiment\"])\n",
        "\n",
        "train_x, test_x, y_train, y_test = train_test_split(train_data, label, stratify = label ,test_size = 0.2, shuffle = True , random_state = 25)"
      ],
      "metadata": {
        "id": "TFBkd-C1FKiM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_positive_reviews=y_train.tolist().count('positive')\n",
        "train_negative_reviews=y_train.tolist().count('negative')\n",
        "test_positive_reviews=y_test.tolist().count('positive')\n",
        "test_negative_reviews=y_test.tolist().count('negative')\n",
        "print(\"Positive reviews in the train dataset : \",train_positive_reviews)\n",
        "print(\"Negative reviews in the train dataset : \",train_negative_reviews)\n",
        "print(\"Positive reviews in the test dataset : \",test_positive_reviews)\n",
        "print(\"Negative reviews in the test dataset : \",test_negative_reviews)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j51qctB_bMFu",
        "outputId": "1a7a2649-4703-4cc8-9831-9f2d91f60a0e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Positive reviews in the train dataset :  20000\n",
            "Negative reviews in the train dataset :  20000\n",
            "Positive reviews in the test dataset :  5000\n",
            "Negative reviews in the test dataset :  5000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer = CountVectorizer( max_features = 1000 )\n",
        "\n",
        "# convert IMDB  data to feature vector matrix\n",
        "train_x = vectorizer.fit_transform(train_x)\n",
        "\n",
        "train_x = train_x.toarray()\n",
        "train_y = y_train\n",
        "\n",
        "print(\"Total training data :\", train_x.shape[0])\n",
        "print(\"Total training data :\", train_y.shape[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rO_9-VQxFiWr",
        "outputId": "dbdda2b0-2a4b-4c74-b5f9-122be32f82d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total training data : 40000\n",
            "Total training data : 40000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_result = vectorizer.transform(test_x)\n",
        "test_result = test_result.toarray()"
      ],
      "metadata": {
        "id": "UNPVhPaRFujN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Logistic regression model** "
      ],
      "metadata": {
        "id": "eGKW8hR6KHIW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = LogisticRegression(penalty='l2')\n",
        "print('-----------------------------------------------------------------------')\n",
        "print('Logistic Regression')\n",
        "model.fit(train_x, train_y)\n",
        "test_pred = model.predict(test_result)\n",
        "print('Accuracy Score : ',accuracy_score(y_test, test_pred))\n",
        "print('F1 Score : ',f1_score(y_test, test_pred, average='weighted'))\n",
        "print('-----------------------------------------------------------------------')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HvRRHyhLF4D_",
        "outputId": "72db314c-132e-4b82-d488-1415b989660c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----------------------------------------------------------------------\n",
            "Logistic Regression\n",
            "Accuracy Score :  0.8608\n",
            "F1 Score :  0.8607518257016196\n",
            "-----------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Sentiment analysis on movie reviews from tweets**"
      ],
      "metadata": {
        "id": "46TGyImFKOPm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "twitter_pred = model.predict(cv_twitter_data)"
      ],
      "metadata": {
        "id": "TWVGxE4yRfs0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "counts = 0\n",
        "for i in range(len(twitter_pred)):\n",
        "  if twitter_pred[i] == 'positive':\n",
        "    counts += 1\n",
        "\n",
        "positive_rate = \"{:.0%}\".format(counts/len(twitter_pred))"
      ],
      "metadata": {
        "id": "_Ymy5E1dSx3I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('positive rate:' + positive_rate)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FnK92dIpTndO",
        "outputId": "76697df0-40cb-407b-83b3-f8c7a6ff70e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "positive rate:32%\n"
          ]
        }
      ]
    }
  ]
}